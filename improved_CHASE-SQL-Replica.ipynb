{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b60b3c58-83be-4e54-9116-9f3268db0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b22f37a0e48659899f330b880ec51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719b9ae96a8846db90638870f34313ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 **Dynamische Evaluierung auf SPIDER-Dataset mit besserer Keyword-Extraktion & SQL-Validierung:**\n",
      "\n",
      "📝 **Frage:** Give me all the phone numbers and email addresses of the workshop groups where services are performed.\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"phone', 'numbers\",', '\"email', 'addresses\",', '\"workshop', 'groups\",', '\"services\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT phone_numbers, email_addresses \n",
      "FROM (\n",
      "  SELECT \n",
      "    workshop_groups.phone_number AS phone_numbers,\n",
      "    workshop_groups.email_address AS email_addresses\n",
      "  FROM customers \n",
      "  JOIN customer_orders ON customers.customer_id = customer_orders.customer_id\n",
      "  JOIN order_items ON customer_orders.order_id = order_items.order_id\n",
      "  JOIN products ON order_items.product_id = products.product_id\n",
      "  WHERE products.category = 'services'\n",
      ") t;\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: t']\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** What is the total number of purchases for members with level 6?\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"total\",', '\"number', 'of', 'purchases\",', '\"members\",', '\"level\",', '\"6\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT COUNT(purchase_id) FROM purchase AS p INNER JOIN member AS m ON p.member_id = m.member_id WHERE m.level = 6;\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join', '⚠️ Ungültige Spalte: where m.level = 6;']\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** What papers have been written by both Peter Mertens and Dina Barbian ?\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"papers\",', '\"written\",', '\"Peter\",', '\"Mertens\",', '\"Dina\",', '\"Barbian\"]', 'Let', 'me', 'know', 'if', \"you'd\", 'like', 'me', 'to', 'help', 'with', 'anything', 'else!']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT p1.paperid \n",
      "FROM writes AS p1 \n",
      "JOIN writes AS p2 ON p1.paperid = p2.citedpaperid AND p1.authorid = p2.authorid \n",
      "WHERE (p1.authorname = 'Peter Mertens' OR p1.authorname = 'Dina Barbian') \n",
      "  AND (p2.authorname = 'Peter Mertens' OR p2.authorname = 'Dina Barbian');\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Spalte: p1.paperid', '⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join']\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** What are the ids of all students who played video games and sports?\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"ids\",', '\"students\",', '\"played\",', '\"video', 'games\",', '\"sports\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT DISTINCT o.order_id \n",
      "FROM customer_orders co \n",
      "JOIN order_items oi ON co.customer_id = oi.product_id \n",
      "WHERE oi.product_name IN ('video games', 'sports');\n",
      "```\n",
      "\n",
      "Note: The above SQL query assumes that the `product_name` column in the `order_items` table contains the names of the products purchased by customers, including video games and sports. This is based on the schema provided where \"products\" table has a column named \"product_name\". If this assumption is incorrect, you may need to adjust the SQL query accordingly.\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Spalte: o.order_id', '⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join', \"⚠️ Ungültige Spalte: where oi.product_name in ('video games', 'sports');\", '⚠️ Ungültige Spalte: sports. this']\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** how many french restaurant are there in palo alto ?\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"french', 'restaurant\",', '\"palo', 'alto\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT COUNT(DISTINCT T3.Name) \n",
      "FROM studio AS T1 \n",
      "JOIN film AS T2 ON T1.Studio_ID = T2.Studio_ID \n",
      "JOIN city AS T3 ON T3.City_ID = T2.departments \n",
      "WHERE T3.Official_Name = 'Palo Alto' AND T2.Name LIKE '%French%Restaurant';\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Spalte: count(distinct t3.name)', '⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join', '⚠️ Ungültige Tabelle: join']\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📊 **Dynamische Evaluierung auf SPIDER-Dataset mit besserer Keyword-Extraktion & SQL-Validierung:**\n",
      "\n",
      "📝 **Frage:** Which problems are reported by the staff with last name \"Bosco\"? Show the ids of the problems.\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"problems\",', '\"reported', 'by\",', '\"staff\",', '\"last', 'name\",', '\"Bosco\",', '\"ids\"]', 'Note', 'that', 'I', \"didn't\", 'include', '\"reported', 'by\"', 'as', 'a', 'keyword', 'because', \"it's\", 'a', 'phrase', 'used', 'to', 'indicate', 'how', 'the', 'staff', 'reported', 'the', 'problems,', 'rather', 'than', 'being', 'an', 'actual', 'concept', 'or', 'entity', 'in', 'the', 'question.']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT DISTINCT p.id \n",
      "FROM Staff s\n",
      "JOIN tip t ON s.staff_id = t.staff_id\n",
      "JOIN farm_competition fc ON t.problem = fc.id\n",
      "WHERE s.last_name = 'Bosco';\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Spalte: p.id', '⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join', '⚠️ Ungültige Tabelle: join', \"⚠️ Ungültige Spalte: where s.last_name = 'bosco';\"]\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** What is the name of the staff that is in charge of the attraction named \"US museum\"?\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"name\",', '\"staff\",', '\"charge\",', '\"attraction\",', '\"named\",', '\"US\",', '\"museum\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT S.first_name, S.last_name \n",
      "FROM Staff AS S \n",
      "JOIN roller_coaster AS RC ON S.Staff_ID = RC.Charge_ID \n",
      "WHERE Name = 'US museum';\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join']\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** Find the first names of the faculty members who are playing Canoeing or Kayaking.\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"first', 'names\",', '\"faculty', 'members\",', '\"playing\",', '\"Canoeing\",', '\"Kayaking\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT T1.first_name FROM Staff AS T1 INNER JOIN tip AS T2 ON T1.staff_id = T2.tip_id WHERE T2.text IN ( 'Canoeing', 'Kayaking' )\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Spalte: t1.first_name', '⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join', \"⚠️ Ungültige Spalte: where t2.text in ( 'canoeing', 'kayaking' )\"]\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** who has written the most syntactic parsing papers ?\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"most\",', '\"syntactic', 'parsing\",', '\"papers\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT authorid \n",
      "FROM writes AS w1 \n",
      "JOIN writes AS w2 ON w1.paperid = w2.citedpaperid \n",
      "GROUP BY w1.authorid \n",
      "ORDER BY COUNT(w1.paperid) DESC LIMIT 1;\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join', '⚠️ Ungültige Spalte: w1.authorid', '⚠️ Ungültige Spalte: count(w1.paperid)']\n",
      "🔄 **Generiere neue Abfrage...**\n",
      "\n",
      "📝 **Frage:** Among all the claims, which claims have a claimed amount larger than the average? List the date the claim was made and the date it was settled.\n",
      "🔑 **Extrahierte Keywords:** ['Here', 'are', 'the', 'extracted', 'keywords:', '[\"claims\",', '\"claimed', 'amount\",', '\"average\",', '\"date', 'the', 'claim', 'was', 'made\",', '\"date', 'it', 'was', 'settled\"]']\n",
      "📌 **Generierte SQL:**\n",
      "```sql\n",
      "SELECT C1.date_made AS \"Date Claim Was Made\", \n",
      "       C2.date_settled AS \"Date It Was Settled\"\n",
      "FROM claim C1\n",
      "JOIN (\n",
      "  SELECT AVG(C3.claimed_amount) as avg_claimed_amount,\n",
      "         date_settled\n",
      "  FROM claim C3\n",
      ") C4 ON (C1.date_settled = C4.date_settled)\n",
      "WHERE C1.claimed_amount > C4.avg_claimed_amount;\n",
      "```\n",
      "❌ **SQL-Fehler gefunden:** ['⚠️ Ungültige Tabelle: from', '⚠️ Ungültige Tabelle: join', '⚠️ Ungültige Tabelle: c4', '⚠️ Ungültige Spalte: (\\n  select avg(c3.claimed_amount) as avg_claimed_amount,\\n         date_settled\\n  from claim c3\\n) c4']\n",
      "🔄 **Generiere neue Abfrage...**\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "import random\n",
    "import sqlparse\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "# ✅ SPIDER-Dataset laden\n",
    "ds = load_dataset(\"CM/spider\")\n",
    "\n",
    "def get_random_questions(dataset, num_samples=5):\n",
    "    \"\"\"\n",
    "    Wählt zufällige Fragen aus der SPIDER-Datenbank aus.\n",
    "    \"\"\"\n",
    "    dataset_list = list(dataset['train'])  # Konvertiere Dataset in eine Liste\n",
    "    return [sample['question'] for sample in random.sample(dataset_list, num_samples)]\n",
    "\n",
    "def get_database_schema():\n",
    "    \"\"\"\n",
    "    Gibt das Datenbankschema in einem einheitlichen Format zurück.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"tables\": [\"highlow\", \"film\", \"studio\", \"Staff\", \"roller_coaster\", \"country\", \n",
    "                   \"tip\", \"member\", \"purchase\", \"author\", \"writes\", \"cite\", \"city\",\n",
    "                   \"farm_competition\", \"customers\", \"customer_orders\", \"order_items\", \"products\"],\n",
    "\n",
    "        \"columns\": {\n",
    "            \"highlow\": [\"state_name\", \"lowest_elevation\"],\n",
    "            \"film\": [\"Studio_ID\", \"Name\", \"Gross_in_dollar\", \"departments\", \"budget\"],\n",
    "            \"studio\": [\"Studio_ID\", \"Name\"],\n",
    "            \"Staff\": [\"first_name\", \"last_name\", \"date_joined_staff\"],\n",
    "            \"roller_coaster\": [\"Name\", \"Country_ID\"],\n",
    "            \"country\": [\"Country_ID\", \"Name\", \"born_state\"],\n",
    "            \"tip\": [\"text\", \"month\"],\n",
    "            \"member\": [\"member_id\", \"level\"],\n",
    "            \"purchase\": [\"purchase_id\", \"member_id\"],\n",
    "            \"author\": [\"authorid\", \"authorname\"],\n",
    "            \"writes\": [\"authorid\", \"paperid\"],\n",
    "            \"cite\": [\"paperid\", \"citedpaperid\"],\n",
    "            \"city\": [\"City_ID\", \"Official_Name\"],\n",
    "            \"farm_competition\": [\"Host_city_ID\"],\n",
    "            \"customers\": [\"customer_id\", \"customer_name\"],\n",
    "            \"customer_orders\": [\"customer_id\", \"order_id\"],\n",
    "            \"order_items\": [\"order_id\", \"product_id\"],\n",
    "            \"products\": [\"product_id\", \"product_name\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "import json\n",
    "import ollama\n",
    "import random\n",
    "import sqlparse\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "# ✅ SPIDER-Dataset laden\n",
    "ds = load_dataset(\"CM/spider\")\n",
    "\n",
    "def get_random_questions(dataset, num_samples=5):\n",
    "    \"\"\"\n",
    "    Wählt zufällige Fragen aus der SPIDER-Datenbank aus.\n",
    "    \"\"\"\n",
    "    dataset_list = list(dataset['train'])  # Konvertiere Dataset in eine Liste\n",
    "    return [sample['question'] for sample in random.sample(dataset_list, num_samples)]\n",
    "\n",
    "def get_database_schema():\n",
    "    \"\"\"\n",
    "    Gibt das Datenbankschema in einem einheitlichen Format zurück.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"tables\": [\"highlow\", \"film\", \"studio\", \"Staff\", \"roller_coaster\", \"country\", \n",
    "                   \"tip\", \"member\", \"purchase\", \"author\", \"writes\", \"cite\", \"city\",\n",
    "                   \"farm_competition\", \"customers\", \"customer_orders\", \"order_items\", \"products\"],\n",
    "\n",
    "        \"columns\": {\n",
    "            \"highlow\": [\"state_name\", \"lowest_elevation\"],\n",
    "            \"film\": [\"Studio_ID\", \"Name\", \"Gross_in_dollar\", \"departments\", \"budget\"],\n",
    "            \"studio\": [\"Studio_ID\", \"Name\"],\n",
    "            \"Staff\": [\"first_name\", \"last_name\", \"date_joined_staff\"],\n",
    "            \"roller_coaster\": [\"Name\", \"Country_ID\"],\n",
    "            \"country\": [\"Country_ID\", \"Name\", \"born_state\"],\n",
    "            \"tip\": [\"text\", \"month\"],\n",
    "            \"member\": [\"member_id\", \"level\"],\n",
    "            \"purchase\": [\"purchase_id\", \"member_id\"],\n",
    "            \"author\": [\"authorid\", \"authorname\"],\n",
    "            \"writes\": [\"authorid\", \"paperid\"],\n",
    "            \"cite\": [\"paperid\", \"citedpaperid\"],\n",
    "            \"city\": [\"City_ID\", \"Official_Name\"],\n",
    "            \"farm_competition\": [\"Host_city_ID\"],\n",
    "            \"customers\": [\"customer_id\", \"customer_name\"],\n",
    "            \"customer_orders\": [\"customer_id\", \"order_id\"],\n",
    "            \"order_items\": [\"order_id\", \"product_id\"],\n",
    "            \"products\": [\"product_id\", \"product_name\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "def extract_keywords(text):\n",
    "    \"\"\"\n",
    "    Extrahiert Schlüsselwörter aus einer Frage mit Ollama.\n",
    "    \"\"\"\n",
    "    few_shot_examples = \"\"\"Extract keywords from the following questions. Examples:\n",
    "    \n",
    "    Question: \"How many heads of the departments are older than 56?\"\n",
    "    Keywords: [\"heads\", \"departments\", \"older\", \"56\"]\n",
    "    \n",
    "    Question: \"List the name, born state, and age of the heads of departments ordered by age.\"\n",
    "    Keywords: [\"name\", \"born state\", \"age\", \"heads\", \"departments\", \"ordered\", \"age\"]\n",
    "    \n",
    "    Question: \"What is the average number of employees of the departments where budget is over 1 billion?\"\n",
    "    Keywords: [\"average\", \"number of employees\", \"departments\", \"budget\", \"over\", \"1 billion\"]\n",
    "    \n",
    "    Now extract keywords from this new question:\n",
    "    Question: \"{text}\"\n",
    "    Keywords:\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.1',\n",
    "        messages=[{\"role\": \"user\", \"content\": few_shot_examples.format(text=text)}]\n",
    "    )\n",
    "    \n",
    "    # 🔹 Falls Antwort JSON enthält, parse es\n",
    "    try:\n",
    "        keywords = json.loads(response['message']['content'])\n",
    "    except json.JSONDecodeError:\n",
    "        keywords = response['message']['content'].strip().replace(\"Keywords:\", \"\").split()\n",
    "\n",
    "    return keywords\n",
    "\n",
    "def generate_sql_with_ollama(question, keywords, database_schema):\n",
    "    \"\"\"\n",
    "    Nutzt Ollama zur SQL-Generierung und stellt sicher, dass nur gültige Tabellen und Spalten verwendet werden.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an SQL expert. Given the following database schema:\n",
    "    {json.dumps(database_schema, indent=2)}\n",
    "\n",
    "    Keywords extracted from the user question: {keywords}\n",
    "\n",
    "    Generate an optimized SQL query that correctly answers the user question:\n",
    "    \"{question}\"\n",
    "\n",
    "    Ensure:\n",
    "    - The query is valid for the given schema.\n",
    "    - Uses appropriate JOINs if needed.\n",
    "    - Uses correct column names from the schema.\n",
    "    - Orders results if necessary.\n",
    "\n",
    "    Return only the SQL query, without any explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.1',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    sql_query = response['message']['content'].strip()\n",
    "\n",
    "    # 🔹 Falls Ollama Erklärungstext enthält, entfernen wir diesen\n",
    "    sql_query = re.sub(r'.*?```sql', '', sql_query, flags=re.DOTALL).strip()\n",
    "    sql_query = re.sub(r'```$', '', sql_query, flags=re.DOTALL).strip()\n",
    "\n",
    "    return sql_query\n",
    "\n",
    "def validate_sql_query(sql_query, database_schema):\n",
    "    \"\"\"\n",
    "    Prüft, ob die SQL-Abfrage nur existierende Tabellen und Spalten verwendet.\n",
    "    \"\"\"\n",
    "    parsed = sqlparse.parse(sql_query)\n",
    "    valid = True\n",
    "    errors = []\n",
    "\n",
    "    # Tabellen & Spalten aus dem Schema holen\n",
    "    tables = set(database_schema[\"tables\"])\n",
    "    columns = {col for table in database_schema[\"columns\"].values() for col in table}\n",
    "\n",
    "    for statement in parsed:\n",
    "        for token in statement.tokens:\n",
    "            token_str = token.value.lower().strip()\n",
    "\n",
    "            # 🔹 Tabellenprüfung (FROM, JOIN)\n",
    "            if \"from\" in token_str or \"join\" in token_str:\n",
    "                table_name = token_str.split()[-1]  # Letztes Wort als Tabellenname\n",
    "                if table_name not in tables:\n",
    "                    errors.append(f\"⚠️ Ungültige Tabelle: {table_name}\")\n",
    "                    valid = False\n",
    "\n",
    "            # 🔹 Spaltenprüfung (table.column)\n",
    "            if \".\" in token_str:\n",
    "                table_col = token_str.split(\".\")\n",
    "                if len(table_col) == 2:\n",
    "                    table, column = table_col\n",
    "                    if table not in tables or column not in columns:\n",
    "                        errors.append(f\"⚠️ Ungültige Spalte: {token_str}\")\n",
    "                        valid = False\n",
    "\n",
    "    return valid, errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 **Dynamische Evaluierung auf SPIDER-Dataset mit besserer Keyword-Extraktion & SQL-Validierung:**\")\n",
    "\n",
    "    # ✅ Zufällige Fragen abrufen\n",
    "    questions = get_random_questions(ds, num_samples=5)\n",
    "\n",
    "    # ✅ Datenbankschema abrufen\n",
    "    db_schema = get_database_schema()\n",
    "\n",
    "    for question in questions:\n",
    "        print(f\"\\n📝 **Frage:** {question}\")\n",
    "\n",
    "        # 🔹 1. Keywords extrahieren\n",
    "        keywords = extract_keywords(question)\n",
    "        print(f\"🔑 **Extrahierte Keywords:** {keywords}\")\n",
    "\n",
    "        # 🔹 2. SQL generieren mit Ollama\n",
    "        sql_query = generate_sql_with_ollama(question, keywords, db_schema)\n",
    "        print(f\"📌 **Generierte SQL:**\\n```sql\\n{sql_query}\\n```\")\n",
    "\n",
    "        # 🔹 3. SQL-Validierung\n",
    "        valid, errors = validate_sql_query(sql_query, db_schema)\n",
    "        if valid:\n",
    "            print(\"✅ **SQL-Abfrage ist gültig!**\")\n",
    "        else:\n",
    "            print(f\"❌ **SQL-Fehler gefunden:** {errors}\")\n",
    "            print(\"🔄 **Generiere neue Abfrage...**\")\n",
    "            sql_query = generate_sql_with_ollama(question, keywords, db_schema)\n",
    "\n",
    "\n",
    "def generate_sql_with_ollama(question, keywords, database_schema):\n",
    "    \"\"\"\n",
    "    Nutzt Ollama zur SQL-Generierung und stellt sicher, dass nur gültige Tabellen und Spalten verwendet werden.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an SQL expert. Given the following database schema:\n",
    "    {json.dumps(database_schema, indent=2)}\n",
    "\n",
    "    Keywords extracted from the user question: {keywords}\n",
    "\n",
    "    Generate an optimized SQL query that correctly answers the user question:\n",
    "    \"{question}\"\n",
    "\n",
    "    Ensure:\n",
    "    - The query is valid for the given schema.\n",
    "    - Uses appropriate JOINs if needed.\n",
    "    - Uses correct column names from the schema.\n",
    "    - Orders results if necessary.\n",
    "\n",
    "    Return only the SQL query, without any explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.1',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    sql_query = response['message']['content'].strip()\n",
    "\n",
    "    # 🔹 Falls Ollama Erklärungstext enthält, entfernen wir diesen\n",
    "    sql_query = re.sub(r'.*?```sql', '', sql_query, flags=re.DOTALL).strip()\n",
    "    sql_query = re.sub(r'```$', '', sql_query, flags=re.DOTALL).strip()\n",
    "\n",
    "    return sql_query\n",
    "\n",
    "def validate_sql_query(sql_query, database_schema):\n",
    "    \"\"\"\n",
    "    Prüft, ob die SQL-Abfrage nur existierende Tabellen und Spalten verwendet.\n",
    "    \"\"\"\n",
    "    parsed = sqlparse.parse(sql_query)\n",
    "    valid = True\n",
    "    errors = []\n",
    "\n",
    "    # Tabellen & Spalten aus dem Schema holen\n",
    "    tables = set(database_schema[\"tables\"])\n",
    "    columns = {col for table in database_schema[\"columns\"].values() for col in table}\n",
    "\n",
    "    for statement in parsed:\n",
    "        for token in statement.tokens:\n",
    "            token_str = token.value.lower().strip()\n",
    "\n",
    "            # 🔹 Tabellenprüfung (FROM, JOIN)\n",
    "            if \"from\" in token_str or \"join\" in token_str:\n",
    "                table_name = token_str.split()[-1]  # Letztes Wort als Tabellenname\n",
    "                if table_name not in tables:\n",
    "                    errors.append(f\"⚠️ Ungültige Tabelle: {table_name}\")\n",
    "                    valid = False\n",
    "\n",
    "            # 🔹 Spaltenprüfung (table.column)\n",
    "            if \".\" in token_str:\n",
    "                table_col = token_str.split(\".\")\n",
    "                if len(table_col) == 2:\n",
    "                    table, column = table_col\n",
    "                    if table not in tables or column not in columns:\n",
    "                        errors.append(f\"⚠️ Ungültige Spalte: {token_str}\")\n",
    "                        valid = False\n",
    "\n",
    "    return valid, errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 **Dynamische Evaluierung auf SPIDER-Dataset mit besserer Keyword-Extraktion & SQL-Validierung:**\")\n",
    "\n",
    "    # ✅ Zufällige Fragen abrufen\n",
    "    questions = get_random_questions(ds, num_samples=5)\n",
    "\n",
    "    # ✅ Datenbankschema abrufen\n",
    "    db_schema = get_database_schema()\n",
    "\n",
    "    for question in questions:\n",
    "        print(f\"\\n📝 **Frage:** {question}\")\n",
    "\n",
    "        # 🔹 1. Keywords extrahieren\n",
    "        keywords = extract_keywords(question)\n",
    "        print(f\"🔑 **Extrahierte Keywords:** {keywords}\")\n",
    "\n",
    "        # 🔹 2. SQL generieren mit Ollama\n",
    "        sql_query = generate_sql_with_ollama(question, keywords, db_schema)\n",
    "        print(f\"📌 **Generierte SQL:**\\n```sql\\n{sql_query}\\n```\")\n",
    "\n",
    "        # 🔹 3. SQL-Validierung\n",
    "        valid, errors = validate_sql_query(sql_query, db_schema)\n",
    "        if valid:\n",
    "            print(\"✅ **SQL-Abfrage ist gültig!**\")\n",
    "        else:\n",
    "            print(f\"❌ **SQL-Fehler gefunden:** {errors}\")\n",
    "            print(\"🔄 **Generiere neue Abfrage...**\")\n",
    "            sql_query = generate_sql_with_ollama(question, keywords, db_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f701ca-a120-4cf6-b9ce-84660cb6148d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
